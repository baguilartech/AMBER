# GitLab CI/CD Pipeline for Amber Discord Bot
# Simplified Auto-DevOps approach
#
# Required CI/CD Variables (set in GitLab Project Settings > CI/CD > Variables):
# ===================================
# 
# APPLICATION SECRETS:
# - DISCORD_TOKEN: Discord bot token
# - DISCORD_CLIENT_ID: Discord application client ID
# - SPOTIFY_CLIENT_ID: Spotify API client ID
# - SPOTIFY_CLIENT_SECRET: Spotify API client secret  
# - YOUTUBE_API_KEY: YouTube API key for music streaming
# - SENTRY_DSN: Sentry error tracking DSN
#
# DOCKER HUB AUTHENTICATION (to avoid rate limits):
# - DOCKERHUB_USERNAME: Docker Hub username
# - DOCKERHUB_TOKEN: Docker Hub access token (not password!)
#
# MONITORING & OBSERVABILITY:
# - ELK_HOST: ELK Stack host for log aggregation
# - ELK_PORT: ELK Stack port (8080 for HTTP input, 5044 for Beats input)
# - GRAFANA_HOST: Grafana host for dashboards
# - GRAFANA_API_TOKEN: Grafana API token for annotations
# - PROMETHEUS_PUSHGATEWAY: Prometheus Push Gateway URL
# - SENTRY_AUTH_TOKEN: Sentry CLI authentication token
# - SENTRY_ORG: Sentry organization name
# - SENTRY_PROJECT: Sentry project name
#
# SONARQUBE (optional):
# - SONAR_HOST_URL: SonarQube server URL  
# - SONAR_TOKEN: SonarQube authentication token
#
# KUBERNETES DEPLOYMENT:
# - KUBE_CONTEXT: Kubernetes context name (if using specific context)
# - ENVIRONMENT_URL: Production environment URL for monitoring
#
# WIKI PUBLISHING (optional):
# - WIKI_ACCESS_TOKEN: GitLab project access token with write_repository scope

image: 
  name: sonarsource/sonar-scanner-cli:11
  entrypoint: [""]

stages:
- build-sonar
- build
- test
- security
- deploy
- review
- dast
- staging
- canary
- production
- incremental rollout 10%
- incremental rollout 25%
- incremental rollout 50%
- incremental rollout 100%
- performance
- cleanup

variables:
  SONAR_USER_HOME: "${CI_PROJECT_DIR}/.sonar"  # Defines the location of the analysis task cache
  GIT_DEPTH: "0"  # Tells git to fetch all the branches of the project, required by the analysis task
  NODE_VERSION: "20"
  npm_config_cache: "$CI_PROJECT_DIR/.npm"
  # Auto-DevOps configuration
  POSTGRES_ENABLED: "false"
  POSTGRES_MANAGED: "false"
  AUTO_DEVOPS_CHART: "auto-deploy-app"
  # Container registry configuration
  DOCKER_TLS_CERTDIR: "/certs"
  CONTAINER_IMAGE: "${CI_REGISTRY_IMAGE}/discord-bot"
  CS_IMAGE: "${CI_REGISTRY_IMAGE}/discord-bot:${CI_COMMIT_SHA}"
  # Observability configuration
  PROMETHEUS_PUSHGATEWAY: "http://${GRAFANA_HOST}:9091"
  # Docker Hub authentication (CI/CD variables: DOCKERHUB_USERNAME, DOCKERHUB_TOKEN)

# Cache template for Node.js projects
.cache_template: &cache_template
  cache:
    key: 
      files:
        - package-lock.json
    paths:
      - node_modules/
      - .npm/
    policy: pull-push

# Docker Hub authentication template
.docker_hub_auth_template: &docker_hub_auth_template
  before_script:
    # Authenticate with Docker Hub to avoid rate limits
    - |
      if [ -n "$DOCKERHUB_USERNAME" ] && [ -n "$DOCKERHUB_TOKEN" ]; then
        echo "Authenticating with Docker Hub..."
        echo "$DOCKERHUB_TOKEN" | docker login -u "$DOCKERHUB_USERNAME" --password-stdin
      else
        echo "Warning: Docker Hub credentials not set. You may hit rate limits."
        echo "Set DOCKERHUB_USERNAME and DOCKERHUB_TOKEN in GitLab CI/CD variables to avoid this."
      fi

# Observability integration template
.observability_template: &observability_template
  after_script:
    # Send pipeline metrics to ELK Stack via Logstash beats (uses CI/CD variables: ELK_HOST, ELK_PORT)
    - |
      if [ -n "$ELK_HOST" ] && [ -n "$ELK_PORT" ]; then
        # Install curl if not available
        if ! command -v curl >/dev/null 2>&1; then
          if command -v apk >/dev/null 2>&1; then
            apk add --no-cache curl
          elif command -v apt-get >/dev/null 2>&1; then
            apt-get update && apt-get install -y curl
          fi
        fi
        
        # Create enhanced pipeline metrics JSON
        JOB_DURATION=$(( $(date +%s) - ${JOB_START_TIME:-$(date +%s)} ))
        METRICS_JSON='{
          "timestamp": "'$(date -Iseconds)'",
          "event": "pipeline_job",
          "log_source": "gitlab_ci",
          "event_type": "pipeline_event",
          "project_name": "'${CI_PROJECT_NAME}'",
          "service_name": "amber-discord-bot",
          "job_name": "'${CI_JOB_NAME}'",
          "job_status": "'${CI_JOB_STATUS:-unknown}'",
          "commit_hash": "'${CI_COMMIT_SHA}'",
          "commit_short_sha": "'${CI_COMMIT_SHORT_SHA}'",
          "branch_name": "'${CI_COMMIT_REF_NAME}'",
          "pipeline_id": "'${CI_PIPELINE_ID}'",
          "pipeline_url": "'${CI_PIPELINE_URL}'",
          "job_id": "'${CI_JOB_ID}'",
          "job_url": "'${CI_JOB_URL}'",
          "stage": "'${CI_JOB_STAGE}'",
          "runner_id": "'${CI_RUNNER_ID}'",
          "runner_description": "'${CI_RUNNER_DESCRIPTION}'",
          "triggered_by": "'${GITLAB_USER_NAME:-system}'",
          "triggered_by_email": "'${GITLAB_USER_EMAIL:-system}'",
          "merge_request_id": "'${CI_MERGE_REQUEST_IID:-null}'",
          "merge_request_title": "'${CI_MERGE_REQUEST_TITLE:-null}'",
          "environment": "'${CI_ENVIRONMENT_NAME:-development}'",
          "tag": "'${CI_COMMIT_TAG:-null}'",
          "duration_seconds": '$JOB_DURATION',
          "gitlab_instance": "'${CI_SERVER_URL}'",
          "gitlab_version": "'${CI_SERVER_VERSION}'",
          "kubernetes_namespace": "amber"
        }'
        
        # Send metrics directly to Logstash
        curl -X POST "http://${ELK_HOST}:${ELK_PORT}" \
          -H "Content-Type: application/json" \
          -d "$METRICS_JSON" || echo "Failed to send metrics to ELK"
      fi
    # Send metrics to Prometheus Push Gateway (uses CI/CD variable: PROMETHEUS_PUSHGATEWAY)
    - |
      if [ -n "$PROMETHEUS_PUSHGATEWAY" ]; then
        # Install curl if not available (reuse installation logic from above)
        if ! command -v curl >/dev/null 2>&1; then
          if command -v apk >/dev/null 2>&1; then
            apk add --no-cache curl
          elif command -v apt-get >/dev/null 2>&1; then
            apt-get update && apt-get install -y curl
          fi
        fi
        
        # Calculate job duration and status
        if [ -n "$CI_JOB_STARTED_AT" ]; then
          JOB_START_TIME=$(date -d "$CI_JOB_STARTED_AT" +%s 2>/dev/null || echo $(date +%s))
        else
          JOB_START_TIME=$(date +%s)
        fi
        JOB_DURATION=$(($(date +%s) - JOB_START_TIME))
        JOB_SUCCESS=$([ "${CI_JOB_STATUS:-unknown}" = "success" ] && echo 1 || echo 0)
        
        # Send pipeline metrics to Prometheus Push Gateway
        printf "gitlab_pipeline_duration_seconds{project=\"%s\",stage=\"%s\",job=\"%s\",branch=\"%s\",pipeline_id=\"%s\"} %s\n" \
          "${CI_PROJECT_NAME}" "${CI_JOB_STAGE}" "${CI_JOB_NAME}" "${CI_COMMIT_REF_NAME}" "${CI_PIPELINE_ID}" "${JOB_DURATION}" | \
          curl -X POST "${PROMETHEUS_PUSHGATEWAY}/metrics/job/gitlab-ci/instance/${CI_JOB_ID}" --data-binary @-
        echo "Metrics sent to Prometheus Push Gateway"
      fi
    # Send annotations to Grafana (uses CI/CD variables: GRAFANA_HOST, GRAFANA_API_TOKEN)
    - |
      if [ -n "$GRAFANA_HOST" ] && [ -n "$GRAFANA_API_TOKEN" ]; then
        # Install curl and glibc if not available
        if ! command -v curl >/dev/null 2>&1; then
          if command -v apk >/dev/null 2>&1; then
            apk add --no-cache curl gcompat
          elif command -v apt-get >/dev/null 2>&1; then
            apt-get update && apt-get install -y curl
          fi
        fi
        curl -X POST "https://${GRAFANA_HOST}:3000/api/annotations" \
          -H "Authorization: Bearer $GRAFANA_API_TOKEN" \
          -H "Content-Type: application/json" \
          --insecure \
          -d '{
            "text": "Pipeline '${CI_JOB_STATUS:-unknown}': '${CI_JOB_NAME}' in '${CI_PROJECT_NAME}'",
            "tags": ["pipeline", "'${CI_PROJECT_NAME}'", "'${CI_COMMIT_REF_NAME}'", "'${CI_JOB_STAGE}'"],
            "time": '$(date +%s)'000
          }' || echo "Failed to send annotation to Grafana"
      fi

# Override Auto-DevOps build job to handle Node.js
build:
  stage: build
  image: node:20
  <<: *cache_template
  before_script:
    - apt-get update && apt-get install -y python3 make g++
    - npm ci --cache .npm --prefer-offline
  script:
    - npm run build
  artifacts:
    paths:
      - dist/
      - node_modules/
    expire_in: 1 hour

# Override Auto-DevOps test job
test:
  stage: test
  image: node:20
  services: []  # No external services needed
  needs:
    - build
  dependencies:
    - build
  before_script:
    - export JOB_START_TIME=$(date +%s)
    - echo "Using artifacts from build job"
  script:
    - npm run test:ci
  coverage: '/All files[^|]*\|[^|]*\s+([\d\.]+)/'
  artifacts:
    when: always
    reports:
      junit: reports/junit.xml
      coverage_report:
        coverage_format: cobertura
        path: coverage/cobertura-coverage.xml
    paths:
      - coverage/
      - reports/
    expire_in: 1 week
  <<: *observability_template

# Override linting (run in test stage)
lint:
  stage: test
  image: node:20
  services: []
  script:
    - npm run lint
    - npm run lint:ci
  artifacts:
    reports:
      junit: reports/lint-results.xml
      codequality: reports/gl-code-quality-report.json
    when: always
    expire_in: 1 week
  <<: *observability_template

# SonarQube Analysis (custom)
sonar_scan:
  stage: test
  image: sonarsource/sonar-scanner-cli:11
  needs:
    - test
  dependencies:
    - test
  cache:
    policy: pull-push
    key: "sonar-cache-$CI_COMMIT_REF_SLUG"
    paths:
      - "${SONAR_USER_HOME}/cache"
      - sonar-scanner/
  before_script:
    - |
      if [ -z "$SONAR_HOST_URL" ]; then
        echo "SONAR_HOST_URL is not set. Skipping SonarQube analysis."
        exit 0
      fi
      if [ -z "$SONAR_TOKEN" ]; then
        echo "SONAR_TOKEN is not set. Skipping SonarQube analysis."
        exit 0
      fi
      if [[ ! "$SONAR_HOST_URL" =~ ^https?:// ]]; then
        export SONAR_HOST_URL="http://${SONAR_HOST_URL}"
      fi
  script: 
    - sonar-scanner -Dsonar.host.url="${SONAR_HOST_URL}" -Dsonar.projectKey="${SONAR_PROJECT_KEY}"
    # Send SonarQube scan event to ELK via Logstash (uses CI/CD variables: ELK_HOST, ELK_PORT)
    - |
      if [ -n "$ELK_HOST" ] && [ -n "$ELK_PORT" ]; then
        # Install curl if not available
        if ! command -v curl >/dev/null 2>&1; then
          if command -v apk >/dev/null 2>&1; then
            apk add --no-cache curl
          elif command -v apt-get >/dev/null 2>&1; then
            apt-get update && apt-get install -y curl
          fi
        fi
        
        # Create enhanced SonarQube metrics JSON
        SONAR_METRICS_JSON='{
          "timestamp": "'$(date -Iseconds)'",
          "event": "sonarqube_scan",
          "log_source": "gitlab_ci",
          "event_type": "pipeline_event",
          "project_name": "'${CI_PROJECT_NAME}'",
          "service_name": "amber-discord-bot",
          "commit_hash": "'${CI_COMMIT_SHA}'",
          "branch_name": "'${CI_COMMIT_REF_NAME}'",
          "sonar_host": "'${SONAR_HOST_URL}'",
          "pipeline_id": "'${CI_PIPELINE_ID}'",
          "job_id": "'${CI_JOB_ID}'",
          "stage": "'${CI_JOB_STAGE}'",
          "scan_tool": "sonarqube"
        }'
        
        # Send metrics directly to Logstash
        curl -X POST "http://${ELK_HOST}:${ELK_PORT}" \
          -H "Content-Type: application/json" \
          -d "$SONAR_METRICS_JSON" || echo "Failed to send SonarQube metrics to ELK"
      fi
  allow_failure: true
  rules:
    - if: $CI_PIPELINE_SOURCE == 'merge_request_event'
    - if: $CI_COMMIT_BRANCH == 'master'
    - if: $CI_COMMIT_BRANCH == 'main'
    - if: $CI_COMMIT_BRANCH == 'develop'
  <<: *observability_template

# Pages for coverage reports
pages:
  stage: deploy
  dependencies:
    - test
  script:
    - mkdir public
    - cp -r coverage/lcov-report/* public/
  artifacts:
    paths:
      - public
    expire_in: 30 days
  rules:
    - if: $CI_COMMIT_BRANCH == 'main'

# Container build and push job
build-container:
  stage: build
  image: docker:20.10.16
  services:
    - docker:20.10.16-dind
  variables:
    DOCKER_TLS_CERTDIR: ""
    DOCKER_HOST: tcp://docker:2375
    DOCKER_DRIVER: overlay2
  before_script:
    - export JOB_START_TIME=$(date +%s)
    - |
      # Wait for Docker daemon to be ready
      until docker info >/dev/null 2>&1; do
        echo "Waiting for Docker daemon..."
        sleep 1
      done
    # Authenticate with Docker Hub to avoid rate limits
    - |
      if [ -n "$DOCKERHUB_USERNAME" ] && [ -n "$DOCKERHUB_TOKEN" ]; then
        echo "Authenticating with Docker Hub..."
        echo "$DOCKERHUB_TOKEN" | docker login -u "$DOCKERHUB_USERNAME" --password-stdin
      else
        echo "Warning: Docker Hub credentials not set. You may hit rate limits."
      fi
    - echo "Logging into GitLab Container Registry..."
    - echo "$CI_REGISTRY_PASSWORD" | docker login -u "$CI_REGISTRY_USER" --password-stdin "$CI_REGISTRY"
  script:
    - echo "Building Discord bot container image..."
    - docker build --build-arg SENTRY_AUTH_TOKEN="$SENTRY_AUTH_TOKEN" --build-arg CA_SERVER_URL="$CA_SERVER_URL" -t $CONTAINER_IMAGE:$CI_COMMIT_SHA -t $CONTAINER_IMAGE:latest .
    - echo "Pushing container image to registry..."
    - docker push $CONTAINER_IMAGE:$CI_COMMIT_SHA
    - docker push $CONTAINER_IMAGE:latest
    # Send container build event to ELK via Logstash (uses CI/CD variables: ELK_HOST, ELK_PORT)
    - |
      if [ -n "$ELK_HOST" ] && [ -n "$ELK_PORT" ]; then
        # Install curl if not available
        if ! command -v curl >/dev/null 2>&1; then
          if command -v apk >/dev/null 2>&1; then
            apk add --no-cache curl
          elif command -v apt-get >/dev/null 2>&1; then
            apt-get update && apt-get install -y curl
          fi
        fi
        
        # Get image size for enhanced metrics
        IMAGE_SIZE=$(docker image inspect $CONTAINER_IMAGE:$CI_COMMIT_SHA --format='{{.Size}}' 2>/dev/null || echo 0)
        
        # Create enhanced container build metrics JSON
        BUILD_METRICS_JSON='{
          "timestamp": "'$(date -Iseconds)'",
          "event": "container_build",
          "log_source": "gitlab_ci",
          "event_type": "pipeline_event",
          "project_name": "'${CI_PROJECT_NAME}'",
          "service_name": "amber-discord-bot",
          "commit_hash": "'${CI_COMMIT_SHA}'",
          "branch_name": "'${CI_COMMIT_REF_NAME}'",
          "container_image": "'${CONTAINER_IMAGE}:${CI_COMMIT_SHA}'",
          "image_size_bytes": '$IMAGE_SIZE',
          "registry": "'${CI_REGISTRY}'",
          "pipeline_id": "'${CI_PIPELINE_ID}'",
          "job_id": "'${CI_JOB_ID}'",
          "stage": "'${CI_JOB_STAGE}'",
          "dockerfile_path": "Dockerfile"
        }'
        
        # Send metrics directly to Logstash
        curl -X POST "http://${ELK_HOST}:${ELK_PORT}" \
          -H "Content-Type: application/json" \
          -d "$BUILD_METRICS_JSON" || echo "Failed to send build metrics to ELK"
      fi
  rules:
    - if: $CI_COMMIT_BRANCH == 'main'
    - if: $CI_COMMIT_BRANCH == 'develop'
    - if: $CI_PIPELINE_SOURCE == 'merge_request_event'
      changes:
        - Dockerfile
        - package*.json
        - src/**/*
  <<: *observability_template

# Container Security Scanning
container_scanning:
  stage: security
  variables:
    CS_IMAGE: "${CI_REGISTRY_IMAGE}/discord-bot:${CI_COMMIT_SHA}"
    CS_DISABLE_DEPENDENCY_LIST: "true"
  dependencies:
    - build-container
  needs:
    - build-container
  rules:
    - if: $CI_COMMIT_BRANCH == 'main'
    - if: $CI_COMMIT_BRANCH == 'develop'
    - if: $CI_PIPELINE_SOURCE == 'merge_request_event'
  allow_failure: true

# Secret Detection (exclude node_modules)
secret_detection:
  variables:
    SECRET_DETECTION_EXCLUDED_PATHS: "node_modules,coverage,dist,reports"

# Disable Auto-DevOps code_quality (we'll use custom ESLint integration)
code_quality:
  rules:
    - when: never

# Release job for tagged versions
# release:
#   stage: deploy
#   image: node:20
#   <<: *cache_template
#   before_script:
#     - npm ci --cache .npm --prefer-offline
#     - |
#       # Configure npm authentication for GitHub registry
#       echo "@baguilartech:registry=https://npm.pkg.github.com/" >> .npmrc
#       echo "//npm.pkg.github.com/:_authToken=${NPM_TOKEN}" >> .npmrc
#   script:
#     - npm run build
#     - npm run test:ci
#     - npm run lint
#     - echo "Creating GitLab release for tag $CI_COMMIT_TAG"
#     - |
#       if [ -n "$CI_COMMIT_TAG" ]; then
#         echo "Publishing to GitHub Package Registry..."
#         npm publish
#       fi
#   artifacts:
#     paths:
#       - dist/
#     expire_in: 1 week
#   rules:
#     - if: $CI_COMMIT_TAG

# Release container image for tagged versions
release-container:
  stage: deploy
  image: docker:20.10.16
  services:
    - docker:20.10.16-dind
  variables:
    DOCKER_TLS_CERTDIR: ""
    DOCKER_HOST: tcp://docker:2375
    DOCKER_DRIVER: overlay2
  before_script:
    - |
      until docker info >/dev/null 2>&1; do
        echo "Waiting for Docker daemon..."
        sleep 1
      done
    # Authenticate with Docker Hub to avoid rate limits
    - |
      if [ -n "$DOCKERHUB_USERNAME" ] && [ -n "$DOCKERHUB_TOKEN" ]; then
        echo "Authenticating with Docker Hub..."
        echo "$DOCKERHUB_TOKEN" | docker login -u "$DOCKERHUB_USERNAME" --password-stdin
      else
        echo "Warning: Docker Hub credentials not set. You may hit rate limits."
      fi
    - echo "Logging into GitLab Container Registry..."
    - echo "$CI_REGISTRY_PASSWORD" | docker login -u "$CI_REGISTRY_USER" --password-stdin "$CI_REGISTRY"
  script:
    - |
      if [ -n "$CI_COMMIT_TAG" ]; then
        VERSION=${CI_COMMIT_TAG#v}
        echo "Building release container for version $VERSION..."
        docker build --build-arg SENTRY_AUTH_TOKEN="$SENTRY_AUTH_TOKEN" --build-arg CA_SERVER_URL="$CA_SERVER_URL" -t $CONTAINER_IMAGE:$VERSION -t $CONTAINER_IMAGE:latest .
        docker push $CONTAINER_IMAGE:$VERSION
        docker push $CONTAINER_IMAGE:latest
        echo "Released container images:"
        echo "  - $CONTAINER_IMAGE:$VERSION"
        echo "  - $CONTAINER_IMAGE:latest"
      fi
  rules:
    - if: $CI_COMMIT_TAG

# Wiki publishing job
publish-wiki:
  stage: deploy
  image: alpine:latest
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
  before_script:
    - apk add --no-cache git rsync
    - git config --global user.email "gitlab-ci@${CI_SERVER_HOST}"
    - git config --global user.name "GitLab CI"
    - |
      # Check if required variables are set
      if [ -z "$WIKI_ACCESS_TOKEN" ]; then
        echo "ERROR: WIKI_ACCESS_TOKEN is not set."
        echo "Please set this variable in your GitLab project settings with a project access token that has 'write_repository' scope."
        exit 1
      fi
  script:
    - echo "Publishing wiki from repository..."
    - |
      # Clone the wiki repository
      git clone https://project-token:${WIKI_ACCESS_TOKEN}@${CI_SERVER_HOST}/${CI_PROJECT_PATH}.wiki.git wiki-repo
      
      # Navigate to wiki repo
      cd wiki-repo
      
      # Clear existing content (preserve .git directory)
      find . -type f ! -path "./.git/*" -delete
      find . -type d ! -path "./.git*" -empty -delete 2>/dev/null || true
      
      # Copy new content from wiki directory
      rsync -av --exclude='.git*' ${CI_PROJECT_DIR}/wiki/ ./
      
      # Add all changes
      git add . || true
      
      # Check if there are changes to commit
      if git diff --cached --quiet; then
        echo "No changes detected in wiki content"
        exit 0
      else
        echo "Changes detected, committing wiki updates..."
        git commit -m "Update wiki from ${CI_COMMIT_SHA:0:8} - ${CI_COMMIT_TITLE}"
        git push origin main
        echo "Wiki updated successfully"
      fi
  after_script:
    - echo "Wiki publishing completed"
  when: always

# Include Auto-DevOps template - This does all the heavy lifting!
include:
  - template: Auto-DevOps.gitlab-ci.yml
  - template: Security/Container-Scanning.gitlab-ci.yml

# Disable Auto-DevOps jobs we don't want
staging:
  rules:
    - when: never

canary:
  rules:
    - when: never

production:
  rules:
    - when: never

# Disable review apps since AMBER is a Discord bot, not a web app
review:
  rules:
    - when: never

stop_review:
  rules:
    - when: never

browser_performance:
  before_script:
    - echo "${ENVIRONMENT_URL}" > environment_url.txt

# ==========================================
# OBSERVABILITY INTEGRATIONS
# ==========================================

# Sentry release management (uses CI/CD variables: SENTRY_AUTH_TOKEN, SENTRY_ORG, SENTRY_PROJECT)
sentry_release:
  stage: deploy
  image: getsentry/sentry-cli:latest
  script:
    - |
      if [ -n "$SENTRY_AUTH_TOKEN" ] && [ -n "$SENTRY_ORG" ] && [ -n "$SENTRY_PROJECT" ]; then
        echo "Creating Sentry release..."
        sentry-cli releases new $CI_COMMIT_SHA
        sentry-cli releases set-commits --auto $CI_COMMIT_SHA
        sentry-cli releases finalize $CI_COMMIT_SHA
        echo "Sentry release created successfully"
      else
        echo "Sentry variables not configured, skipping release creation"
      fi
  rules:
    - if: $CI_COMMIT_BRANCH == 'main'
    - if: $CI_COMMIT_TAG
  allow_failure: true
  <<: *observability_template

# GitLab Agent deployment for production (recommended)
deploy_production:
  stage: deploy
  image: alpine:latest
  before_script:
    - export JOB_START_TIME=$(date +%s)
    - apk add --no-cache kubectl gettext bash  # install kubectl, envsubst and bash
  variables:
    # GitLab Agent context (following GitLab documentation)
    # Format: path/to/agent/project:agent-name
    # This will be auto-populated by GitLab if agent is configured
    KUBE_CONTEXT: ${CI_PROJECT_PATH}:production
    # Rollback behavior control
    ROLLBACK_ON_FAILURE: "true"
  script:
    - echo "Deploying to production via GitLab Agent..."
    # Export environment variables for substitution
    - export DISCORD_TOKEN="$DISCORD_TOKEN"
    - export DISCORD_CLIENT_ID="$DISCORD_CLIENT_ID"
    - export SPOTIFY_CLIENT_ID="$SPOTIFY_CLIENT_ID" 
    - export SPOTIFY_CLIENT_SECRET="$SPOTIFY_CLIENT_SECRET"
    - export YOUTUBE_API_KEY="$YOUTUBE_API_KEY"
    - export SENTRY_DSN="$SENTRY_DSN"
    - export ELK_HOST="$ELK_HOST"
    - export ELK_PORT="$ELK_PORT"
    - export GRAFANA_HOST="$GRAFANA_HOST"
    - export REGISTRY_URL="$REGISTRY_URL"
    - export CI_REGISTRY_IMAGE="$CI_REGISTRY_IMAGE"
    - export IMAGE_TAG="${CI_COMMIT_TAG:-latest}"
    - export CI_JOB_TOKEN="$CI_JOB_TOKEN"
    # Create environment URL file for Auto-DevOps
    - echo "${ENVIRONMENT_URL}" > environment_url.txt
    # Store current deployment state for potential rollback
    - kubectl get deployment amber-discord-bot -n amber -o yaml > /tmp/previous-deployment.yaml 2>/dev/null || echo "No previous deployment found"
    # Run production deployment script with error handling
    - cd k8s/prod
    - ls -la
    - |
      if ! bash deploy.sh; then
        echo "âŒ Deployment failed!"
        if [ "$ROLLBACK_ON_FAILURE" = "true" ]; then
          echo "ðŸ”„ Initiating rollback..."
          if [ -f /tmp/previous-deployment.yaml ] && [ -s /tmp/previous-deployment.yaml ]; then
            echo "ðŸ“¦ Rolling back to previous deployment..."
            kubectl apply -f /tmp/previous-deployment.yaml || echo "âš ï¸ Rollback failed - no previous state available"
            kubectl rollout status deployment/amber-discord-bot -n amber --timeout=120s || echo "âš ï¸ Rollback status check failed"
          else
            echo "ðŸ—‘ï¸ No previous deployment found - cleaning up failed deployment..."
            kubectl delete deployment amber-discord-bot -n amber 2>/dev/null || echo "No deployment to clean up"
          fi
        fi
        exit 1
      fi
    - echo "âœ… Production deployment completed via GitLab Agent"
  environment:
    name: production
    url: ${ENVIRONMENT_URL}  # AMBER is a Discord bot - URL points to cluster monitoring
    kubernetes:
      namespace: amber
    deployment_tier: production
    action: start
  when: manual
  rules:
    - if: $CI_COMMIT_BRANCH == 'main'
  needs:
    - build-container
  <<: *observability_template

# Manual cleanup jobs for production environment
cleanup_production:
  stage: deploy
  image: alpine:latest
  before_script:
    - export JOB_START_TIME=$(date +%s)
    - apk add --no-cache kubectl gettext bash
  variables:
    KUBE_CONTEXT: ${CI_PROJECT_PATH}:production
  script:
    - echo "ðŸ—‘ï¸ Force cleaning up production deployment..."
    # Configure kubectl for GitLab Agent (same as deploy_production)
    - |
      if [ -n "$KUBECONFIG" ]; then
        echo "ðŸ“„ Using KUBECONFIG: $KUBECONFIG"
        kubectl config get-contexts || exit 1
        if [ -n "$KUBE_CONTEXT" ]; then
          echo "ðŸŽ¯ Setting context to: $KUBE_CONTEXT"
          kubectl config use-context "$KUBE_CONTEXT" || exit 1
        fi
        # Test connection
        kubectl cluster-info --request-timeout=10s || exit 1
        echo "âœ… Successfully connected to Kubernetes cluster"
      else
        echo "âŒ Error: No KUBECONFIG provided"
        exit 1
      fi
    - |
      # Force delete deployment
      kubectl delete deployment amber-discord-bot -n amber --force --grace-period=0 || echo "No deployment to delete"
      
      # Force delete all pods to ensure clean restart
      kubectl delete pods --all -n amber --force --grace-period=0 || echo "No pods to delete"
      
      # Delete services
      kubectl delete service amber-discord-bot amber-discord-bot-external -n amber || echo "No services to delete"
      
      # Delete configmaps
      kubectl delete configmap amber-config amber-config-env -n amber || echo "No configmaps to delete"
      
      # Delete secrets
      kubectl delete secret amber-secrets-env gitlab-registry -n amber || echo "No secrets to delete"
      
      # Clean up filebeat resources
      kubectl delete daemonset filebeat-amber -n amber || echo "No filebeat daemonset to delete"
      kubectl delete configmap filebeat-config -n amber || echo "No filebeat config to delete"
      kubectl delete serviceaccount filebeat -n amber || echo "No filebeat serviceaccount to delete"
      kubectl delete clusterrole filebeat-amber || echo "No filebeat clusterrole to delete"
      kubectl delete clusterrolebinding filebeat-amber || echo "No filebeat clusterrolebinding to delete"
      
      echo "âœ… Force cleanup completed"
  environment:
    name: production
    action: stop
  when: manual
  rules:
    - if: $CI_COMMIT_BRANCH == 'main'
  <<: *observability_template

# Rollback to previous version (manual)
rollback_production:
  stage: deploy
  image: alpine:latest
  before_script:
    - export JOB_START_TIME=$(date +%s)
    - apk add --no-cache kubectl gettext bash
  variables:
    KUBE_CONTEXT: ${CI_PROJECT_PATH}:production
  script:
    - echo "ðŸ”„ Rolling back production deployment..."
    # Configure kubectl for GitLab Agent
    - |
      if [ -n "$KUBECONFIG" ]; then
        echo "ðŸ“„ Using KUBECONFIG: $KUBECONFIG"
        kubectl config get-contexts || exit 1
        if [ -n "$KUBE_CONTEXT" ]; then
          echo "ðŸŽ¯ Setting context to: $KUBE_CONTEXT"
          kubectl config use-context "$KUBE_CONTEXT" || exit 1
        fi
        # Test connection
        kubectl cluster-info --request-timeout=10s || exit 1
      else
        echo "âŒ Error: No KUBECONFIG provided"
        exit 1
      fi
    - |
      # Use kubectl rollout to rollback to previous revision
      if kubectl rollout history deployment/amber-discord-bot -n amber; then
        kubectl rollout undo deployment/amber-discord-bot -n amber
        kubectl rollout status deployment/amber-discord-bot -n amber --timeout=300s
        echo "âœ… Rollback completed successfully"
        kubectl get pods -n amber
      else
        echo "âŒ No deployment history found for rollback"
        exit 1
      fi
  environment:
    name: production
    url: ${ENVIRONMENT_URL}
  when: manual
  rules:
    - if: $CI_COMMIT_BRANCH == 'main'
  <<: *observability_template



